{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of utils_residual.ipynb","provenance":[{"file_id":"1BH5pmfDhiRwshM_0jiWha4zSWlQTJuRb","timestamp":1572475857785}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ogchcEFUUJz6","colab_type":"code","colab":{}},"source":["import os \n","import numpy as np \n","import tensorflow as tf\n","#h5py package is a Pythonic interface to the HDF5 binary data format. \n","#It lets you store huge amounts of numerical data, and easily manipulate that data from NumPy\n","import h5py\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-2J9IaoYrD7","colab_type":"code","colab":{}},"source":["def load_dataset():\n","    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n","    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n","    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n","\n","    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n","    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n","    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n","\n","    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n","    \n","    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n","    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n","    \n","    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bwp4uL-mZB9g","colab_type":"code","colab":{}},"source":[" #Creates a list of random minibatches from (X, Y)\n"," def random_mini_batches(x,y,mini_batch_size=64,seed=0):\n","    m = X.shape[0]                  # number of training examples\n","    mini_batches = []\n","    np.random.seed(seed)\n","    \n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[permutation,:,:,:]\n","    shuffled_Y = Y[permutation,:]\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n","        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0: # handel if the last batch != 64\n","        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n","        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    return mini_batches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ5LxQ3qfgIq","colab_type":"code","colab":{}},"source":["#convert the data to one hot encoder \n","def convert_to_one_hot(Y,c):\n","  Y=np.eye(c)[Y.reshape(-1)].T\n","  return Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UidffjArkuxA","colab_type":"code","colab":{}},"source":["#Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n","#X the dataset placeholder with shape(input_size,number of examples)\n","#parameters are the weights & biases \n","\n","def forward_propagation_for_prediction(X,parameters):\n","  W1=parameters['W1']\n","  b1= W1=parameters['b1']\n","  W2=parameters['W2']\n","  b2= W1=parameters['b2']\n","  W3=parameters['W3']\n","  b3= W1=parameters['b3']\n","\n","  Z1=tf.add(tf.matmul(W1,x),b1)\n","  A1=tf.nn.relu(Z1)\n","\n","  Z2=tf.add(tf.matmul(W2,x),b2)\n","  A2=tf.nn.relu(Z2)\n","\n","  Z3=tf.add(tf.matmul(W3,x),b3)\n","  A3=tf.nn.relu(Z3)\n","\n","  return Z3\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"owx5ANczyAFe","colab_type":"code","colab":{}},"source":["#predict \n","def predict(X,parameters):\n","   \n","    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n","    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n","    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n","    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n","    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n","    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n","    \n","    params = {\"W1\": W1,\n","              \"b1\": b1,\n","              \"W2\": W2,\n","              \"b2\": b2,\n","              \"W3\": W3,\n","              \"b3\": b3}\n","    \n","    x = tf.placeholder(\"float\", [12288, 1])\n","    z3=forward_propagation_for_prediction(x,params)\n","    p=tf.argmax(z3)\n","    sess=tf.Session()\n","    prediction=sess.run(p,feed_dict={x:X})\n","    return predicition\n"],"execution_count":0,"outputs":[]}]}